{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNcJwp3bPtXCnYFFi6PIxAa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevin1109500/MACHINE-LEARNING/blob/main/DIABETES_PREDICTION_DUE_TO_OBESITY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7DdLnJ15BsP"
      },
      "outputs": [],
      "source": [
        "pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import r2_score,accuracy_score,precision_score,recall_score,classification_report,confusion_matrix,f1_score\n",
        "\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "jr5yonVN5awQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading data from excel file named obesity project\n",
        "df = pd.read_excel('/content/obesity project (4).xls',sheet_name='new trial group')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HSmjZ-_b6OUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of Dataset: {} rows , {} columns\".format(df.shape[0],df.shape[1]))"
      ],
      "metadata": {
        "id": "jJdh5N1o6cFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "4b7hhX2o6cHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ofjJ-qIm6cKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "apRt0REa6cMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "cIexdD5w6cO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Missing_Values(data):\n",
        "    variable_name = []\n",
        "    total_value = []\n",
        "    total_missing_value = []\n",
        "    missing_value_rate = []\n",
        "    unique_value_list = []\n",
        "    total_unique_value = []\n",
        "    data_type = []\n",
        "\n",
        "    for col in data.columns:\n",
        "        variable_name.append(col)\n",
        "        data_type.append(data[col].dtype)\n",
        "        total_value.append(data[col].shape[0])\n",
        "        total_missing_value.append(data[col].isnull().sum())\n",
        "        missing_value_rate.append(round(data[col].isnull().sum()/data[col].shape[0],4))\n",
        "        unique_value_list.append(data[col].unique())\n",
        "        total_unique_value.append(len(data[col].unique()))\n",
        "\n",
        "    missing_data=pd.DataFrame({\"Variable\":variable_name,\\\n",
        "                               \"#_Total_Value\":total_value,\\\n",
        "                               \"#_Total_Missing_Value\":total_missing_value,\\\n",
        "                               \"%_Missing_Value_Rate\":missing_value_rate,\\\n",
        "                               \"Data_Type\":data_type,\"Unique_Value\":unique_value_list,\\\n",
        "                               \"Total_Unique_Value\":total_unique_value\n",
        "                              })\n",
        "\n",
        "    missing_data = missing_data.set_index(\"Variable\")\n",
        "    return missing_data.sort_values(\"#_Total_Missing_Value\",ascending=False)"
      ],
      "metadata": {
        "id": "3VNa0SIG6cRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Missing_Values(df)"
      ],
      "metadata": {
        "id": "fEX3UhAh6cTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fuVEEVcj6cVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HK3IfE5t6cas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for correlation bet the features with null values\n",
        "msno.heatmap(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DpC7oVYC6cdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['after intervention triglycerides', 'after intervention Total cholestrol', 'after intervention ldl',\n",
        "              'after intervention', 'trial HBA1C', 'AFTER INTERVENTION  cho intake', 'AFTER INTERVENTION PROTEIN INTAKE',\n",
        "              'after intervention calories', 'AFTER INTERVENTION  fat intake', 'after trial FBS', 'after trial PPBS',\n",
        "              'after intervention BMI (Kg/m2)'], axis = 1)\n",
        "\n",
        "df = df.drop(['Prescribed Calories','patient intake Calories','protein intake','cho intake','fat intake','follow up wt','remarks'], axis = 1)"
      ],
      "metadata": {
        "id": "U4pBicIX6cgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "OCwft85666hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "-DLFn9g-66jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing null values with median of respectively column median\n",
        "df[['baseline FBS', 'PPBS','baseline HBA1C','Total cholestrol','triglycerides','hdl','ldl']] = df[['baseline FBS', 'PPBS','baseline HBA1C','Total cholestrol','triglycerides','hdl','ldl']].fillna(df[['baseline FBS', 'PPBS','baseline HBA1C','Total cholestrol','triglycerides','hdl','ldl']].median())"
      ],
      "metadata": {
        "id": "Q0J3T1Wm66l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of Dataset Before dropping the null values: {} rows , {} columns\".format(df.shape[0],df.shape[1]+18))\n",
        "df.dropna(axis=0,inplace = True)\n",
        "print(\"Size of Dataset After dropping the null values: {} rows , {} columns\".format(df.shape[0],df.shape[1]))"
      ],
      "metadata": {
        "id": "6cOKySBf66pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "rnQCmg2866ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age (yrs)'].value_counts()"
      ],
      "metadata": {
        "id": "Th-4NKFw7D1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "XxPRuvEx7D8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Diagnosis'] = df['Diagnosis'].replace(['diabetes mellitus,obese class1'], 'diabetes mellitus obese class 1')\n",
        "df['Diagnosis'] = df['Diagnosis'].replace(['diabetic mellitus,obese class1'], 'diabetes mellitus obese class 1')\n",
        "df['Diagnosis'] = df['Diagnosis'].replace(['diabetic mellitus,obese class2'], 'diabetes mellitus obese class 2')\n",
        "df['Diagnosis'] = df['Diagnosis'].replace(['diabetic mellitus,obese grade 2'], 'diabetes mellitus obese class 2')"
      ],
      "metadata": {
        "id": "XA-ckwba7ECJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "eRDRmYHg7EIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['job type'].value_counts()"
      ],
      "metadata": {
        "id": "fqyemg6Q7Lix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"job type\"],axis=1,inplace = True)"
      ],
      "metadata": {
        "id": "V7z6sL_U7Z7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['physical activity'].value_counts()"
      ],
      "metadata": {
        "id": "V4cO03Mc7Lpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['physical activity'] = df['physical activity'].replace(['walking 1/2hr','walking 30min/day','walking1/2hr','walking 35mins a day','walking daily 1/2hr','walking 1/2hr,hypoglycemia','walking 30mins'], 'walking 30 mins')\n",
        "df['physical activity'] = df['physical activity'].replace(['walking 1 hr/day','walking 1hr','swimming 1hr','walking 1hr/day','walking 50mins a day'], 'walking 1 hr')\n",
        "df['physical activity'] = df['physical activity'].replace(['walking 10-15mins','walking 20mins/day','walking 20min/day'], 'walking 15 mins')\n",
        "df['physical activity'] = df['physical activity'].replace(['walking 45mins','walking 45min/day','walking 40mins/day','walking 45-1hr','walking 45mins a day'], 'walking 45 mins')\n",
        "df['physical activity'] = df['physical activity'].replace(['walking 1hr weekly 3 times','walking weekly \\nthree times 20mins'], 'walking 3hr weekly')\n",
        "df['physical activity'] = df['physical activity'].replace(['exercise for 1hr'], 'exercise 1hr')"
      ],
      "metadata": {
        "id": "1ShXX7577Lwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['physical activity'].value_counts()"
      ],
      "metadata": {
        "id": "JpzutsPT7L1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"physical activity\"],axis=1,inplace = True)"
      ],
      "metadata": {
        "id": "ZyMSLfck7L7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = df.select_dtypes(include=np.number).columns.tolist()\n",
        "for cols in numeric_columns:\n",
        "  if cols != 'Sex':\n",
        "    print(f\"\\n\\n {cols} \\n\")\n",
        "    mean = np.mean(df[cols])\n",
        "    std = np.std(df[cols])\n",
        "    print('mean is', mean)\n",
        "    print('std. deviation is', std)\n",
        "    threshold = 3\n",
        "    outlier = []\n",
        "    for i in df[cols]:\n",
        "        z = (i-mean)/std\n",
        "        if z > threshold:\n",
        "            outlier.append(i)\n",
        "    if len(outlier) != 0:\n",
        "      print('outliers are', outlier)\n",
        "    else:\n",
        "      print(\"No Outliers\")"
      ],
      "metadata": {
        "id": "SdoKjpOP9Gl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = df.select_dtypes(include=np.number).columns.tolist()\n",
        "for cols in numeric_columns:\n",
        "  if cols != 'Sex':\n",
        "    x = math.floor(df[cols].quantile(0.00))\n",
        "    y = math.floor(df[cols].quantile(0.95))\n",
        "\n",
        "    df[cols] = np.where(df[cols] < x, x,df[cols])\n",
        "    df[cols] = np.where(df[cols] > y, y,df[cols])"
      ],
      "metadata": {
        "id": "5NBSTPcE9J58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy(deep=True)"
      ],
      "metadata": {
        "id": "PkCvwFnI9KDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Diagnosis'] = pd.Categorical(df1['Diagnosis']).codes\n",
        "df1['Diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "XW9Ss-Bf9KMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df1.corr() # Generate correlation matrix\n",
        "x = list(df_corr.columns)\n",
        "y = list(df_corr.index)\n",
        "z = np.array(df_corr)\n",
        "\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z,\n",
        "    x = x,\n",
        "    y = y,\n",
        "    annotation_text = np.around(z, decimals=2),\n",
        "    hoverinfo='z',\n",
        "    colorscale='Viridis',\n",
        "    zmax = 1,\n",
        "    zmin = -1\n",
        "    )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wGt5P4Nn9P62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "iTOYCu2S9QB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy(deep=True)"
      ],
      "metadata": {
        "id": "soQnX-qX9QHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.get_dummies(df2, columns = ['Diagnosis'])"
      ],
      "metadata": {
        "id": "FVZhgDya9QOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df2.corr() # Generate correlation matrix\n",
        "x = list(df_corr.columns)\n",
        "y = list(df_corr.index)\n",
        "z = np.array(df_corr)\n",
        "\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z,\n",
        "    x = x,\n",
        "    y = y,\n",
        "    annotation_text = np.around(z, decimals=2),\n",
        "    hoverinfo='z',\n",
        "    colorscale='Viridis',\n",
        "    zmax = 1,\n",
        "    zmin = -1\n",
        "    )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CcsMEj_L9Xui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Diagnosis'] = pd.Categorical(df['Diagnosis']).codes"
      ],
      "metadata": {
        "id": "9aX5QKtg9X2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vrXKL-IA9X7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Diagnosis']\n",
        "x = df.drop(['Diagnosis'],axis = 1)"
      ],
      "metadata": {
        "id": "bZQTIo4_9etG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# our data is a imbalanced data\n",
        "y.value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "id": "N-JNk0Gf9ez8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y,\n",
        "                                                    stratify=y,\n",
        "                                                    test_size=0.25)"
      ],
      "metadata": {
        "id": "a1n8WCkY9e3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts(),y_test.value_counts())"
      ],
      "metadata": {
        "id": "7UZhhCMt9e5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cols in X_train.columns:\n",
        "  if cols != 'Sex':\n",
        "    X_train[cols] = StandardScaler().fit_transform(np.array(X_train[cols]).reshape(-1, 1))\n",
        "    X_test[cols] = StandardScaler().fit_transform(np.array(X_test[cols]).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "uGPQv0r_9e8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before OverSampling, counts of label '2': {}\".format(sum(y_train == 2)))\n",
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "\n",
        "sm = SMOTE(random_state = 42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res == 2)))\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
      ],
      "metadata": {
        "id": "Nyp1T2oN9e_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric = None)\n",
        "\n",
        "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models)"
      ],
      "metadata": {
        "id": "POm2B3M49fCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbc = XGBClassifier()\n",
        "\n",
        "xgbc.fit(X_train_res, y_train_res)\n",
        "y_pred = xgbc.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "E7QcehsI9rrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to training data\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "xNQGcIAf9rwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbc = XGBClassifier(learning_rate =  0.01, max_depth = 5, min_child_weight = 1, n_estimators = 100, subsample = 0.8)\n",
        "\n",
        "xgbc.fit(X_train_res, y_train_res)\n",
        "y_pred = xgbc.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "btaHcKuH9r0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier()\n",
        "\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "tWCktlAo9r3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': [None, 'balanced', {0: 0.3, 1: 0.7}]\n",
        "}\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "Classifier = RandomForestClassifier()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=Classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to training data\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "KsBlzGPg9r6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(class_weight = None, max_depth = 5, max_features = 'sqrt', min_samples_split = 2, n_estimators = 100)\n",
        "\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "sns.heatmap(confusion_matrix(y_pred,y_test), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rR_o3E9L9r-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "sns.heatmap(confusion_matrix(y_pred,y_test), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-aaQ7MyH9sBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'max_iter': [50, 100, 200],\n",
        "    'class_weight': [None, 'balanced', {0: 0.3, 1: 0.7}]\n",
        "}\n",
        "\n",
        "# Initialize LogisticRegression\n",
        "Classifier = LogisticRegression()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=Classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to training data\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "RFa7ZzWq994L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression(C = 1, class_weight = {0: 0.3, 1: 0.7}, max_iter = 100, penalty = 'l1', solver = 'saga')\n",
        "\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "sns.heatmap(confusion_matrix(y_pred,y_test), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_2lHap-D9-BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier =  KNeighborsClassifier()\n",
        "\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "sns.heatmap(confusion_matrix(y_pred,y_test), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m6jphd0H9-E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2, 3],\n",
        "    'leaf_size': [20, 30, 40]\n",
        "}\n",
        "\n",
        "# Initialize KNeighborsClassifier\n",
        "Classifier = KNeighborsClassifier()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=Classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to training data\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "hjhkkrVo9-Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVC()\n",
        "\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "sns.heatmap(confusion_matrix(y_pred,y_test), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rv0YY4Zl-GBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree': [2, 3, 4],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1]\n",
        "}\n",
        "\n",
        "# Initialize KNeighborsClassifier\n",
        "Classifier = SVC()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=Classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to training data\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "J4wCHVA--GJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVC(C = 1, class_weight = None, degree = 2, gamma = 'scale', kernel = 'linear')\n",
        "\n",
        "classifier.fit(X_train_res, y_train_res)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "sns.heatmap(confusion_matrix(y_pred,y_test), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ig0UX-CH-GOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(learning_rate =  0.01, max_depth = 5, min_child_weight = 1, n_estimators = 100, subsample = 0.8)\n",
        "\n",
        "model.fit(X_train_res, y_train_res)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy score : \",accuracy_score(y_pred,y_test))\n",
        "print(\"r2 score : \",r2_score(y_pred,y_test))\n",
        "print(\"precision score : \",precision_score(y_pred,y_test,average='micro'))\n",
        "print(\"recall score : \",recall_score(y_pred,y_test,average='micro'))\n",
        "print(\"f1 score : \",f1_score(y_pred,y_test,average='micro'))\n",
        "print(\"\\nclassification report \\n\")\n",
        "sns.heatmap(confusion_matrix(y_pred,y_test), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wG09FZ1p-GRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}